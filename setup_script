#!/bin/bash

# SynthesisTalk LLM Integration Setup Script
# Run this script to set up your development environment

echo "🚀 Setting up SynthesisTalk LLM Integration..."
echo "================================================"

# Check if Python is installed
if ! command -v python3 &> /dev/null; then
    echo "❌ Python 3 is not installed. Please install Python 3.8 or higher."
    exit 1
fi

echo "✅ Python 3 found: $(python3 --version)"

# Check if pip is installed
if ! command -v pip3 &> /dev/null; then
    echo "❌ pip3 is not installed. Please install pip."
    exit 1
fi

echo "✅ pip3 found"

# Create virtual environment if it doesn't exist
if [ ! -d "venv" ]; then
    echo "📦 Creating virtual environment..."
    python3 -m venv venv
    echo "✅ Virtual environment created"
else
    echo "✅ Virtual environment already exists"
fi

# Activate virtual environment
echo "🔄 Activating virtual environment..."
source venv/bin/activate

# Upgrade pip
echo "⬆️  Upgrading pip..."
pip install --upgrade pip

# Install requirements
echo "📚 Installing Python packages..."
if [ -f "requirements.txt" ]; then
    pip install -r requirements.txt
    echo "✅ Requirements installed from requirements.txt"
else
    echo "⚠️  requirements.txt not found. Installing basic packages..."
    pip install openai python-dotenv requests beautifulsoup4 PyPDF2 fastapi uvicorn pydantic python-multipart aiofiles
fi

# Check if .env file exists
if [ ! -f ".env" ]; then
    echo "📝 Creating .env file template..."
    cat > .env << EOF
# LLM Configuration
MODEL_SERVER=NGU
NGU_API_KEY=ngu-y8PCtqZW9R
NGU_BASE_URL=https://ngullama.femtoid.com/v1
NGU_MODEL=qwen2.5-coder:7b

# Alternative GROQ Configuration (uncomment to use)
# MODEL_SERVER=GROQ
# GROQ_API_KEY=your_groq_api_key_here
# GROQ_BASE_URL=https://api.groq.com/openai/v1
# GROQ_MODEL=llama-3.1-70b-versatile
EOF
    echo "✅ .env file created with your NGU configuration"
else
    echo "✅ .env file already exists"
fi

# Create necessary directories
echo "📁 Creating project directories..."
mkdir -p uploads
mkdir -p exports
mkdir -p logs
echo "✅ Directories created"

# Test the setup
echo "🧪 Testing the setup..."
if python3 -c "from llm_client import ask_llm; print('LLM import successful')" 2>/dev/null; then
    echo "✅ LLM client imports successfully"
else
    echo "⚠️  LLM client import failed. Check your configuration."
fi

echo ""
echo "🎉 Setup complete!"
echo "================================================"
echo ""
echo "Next steps:"
echo "1. Activate the virtual environment: source venv/bin/activate"
echo "2. Test your setup: python test_llm.py"
echo "3. Start the FastAPI server: python main.py"
echo "4. Or run with uvicorn: uvicorn main:app --reload"
echo ""
echo "Your LLM Integration is ready for development! 🚀"